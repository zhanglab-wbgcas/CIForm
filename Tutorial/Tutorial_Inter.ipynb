{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f964c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score\n",
    "from torch.utils.data import (DataLoader,Dataset)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Torch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "same_seeds(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e50b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(gap, adata, Traindata_paths):\n",
    "    X = adata.X\n",
    "    single_cell_list = []\n",
    "    for single_cell in X:\n",
    "        feature = []\n",
    "        length = len(single_cell)\n",
    "        for k in range(0, length, gap):\n",
    "            if (k + gap <= length):\n",
    "                a = single_cell[k:k + gap]\n",
    "            else:\n",
    "                a = single_cell[length - gap:length]\n",
    "\n",
    "            a = preprocessing.scale(a)\n",
    "            feature.append(a)\n",
    "        feature = np.asarray(feature)\n",
    "        single_cell_list.append(feature)\n",
    "\n",
    "    single_cell_list = np.asarray(single_cell_list)\n",
    "    if(Traindata_paths != None):\n",
    "\n",
    "        y_trains = []\n",
    "        for path in Traindata_paths:\n",
    "            y_train = pd.read_csv(path + \"Labels.csv\")\n",
    "            y_train = y_train.T\n",
    "            y_train = y_train.values[0]\n",
    "            y_trains.extend(y_train)\n",
    "\n",
    "        cell_types = []\n",
    "        for i in y_trains:\n",
    "            i = str(i).upper()\n",
    "            if (not cell_types.__contains__(i)):\n",
    "                cell_types.append(i)\n",
    "\n",
    "        return single_cell_list, y_trains, cell_types\n",
    "    else:\n",
    "        return single_cell_list\n",
    "\n",
    "def getNewData(cells, cell_types):\n",
    "    labels = []\n",
    "    for i in range(len(cells)):\n",
    "        cell = cells[i]\n",
    "        cell = str(cell).upper()\n",
    "\n",
    "        if (cell_types.__contains__(cell)):\n",
    "            indexs = cell_types.index(cell)\n",
    "            labels.append(indexs + 1)\n",
    "        else:\n",
    "            labels.append(0)  # 0 denotes the unknowns cell types\n",
    "\n",
    "    return np.asarray(labels)\n",
    "\n",
    "\n",
    "def getData(gap, Traindata_paths, Train_names,\n",
    "            Testdata_path, Testdata_name, topgenes):\n",
    "    all_adata = sc.AnnData\n",
    "    train_adata = sc.AnnData\n",
    "    for sa in range(0, len(Train_names)):\n",
    "        temp_adata = sc.read_csv(Traindata_paths[sa] + Train_names[sa] + \".csv\", first_column_names=True)\n",
    "        temp_adata.var_names = [str(i).upper() for i in temp_adata.var_names]\n",
    "        temp_adata.var_names_make_unique()\n",
    "\n",
    "        train_adata = train_adata.concatenate(temp_adata)\n",
    "        train_adata.var_names_make_unique()\n",
    "\n",
    "    Trainadata_num = len(train_adata)\n",
    "    test_adata = sc.read_csv(Testdata_path + Testdata_name + \".csv\")\n",
    "    test_adata.var_names_make_unique()\n",
    "    sc.pp.log1p(train_adata)\n",
    "    sc.pp.log1p(test_adata)\n",
    "\n",
    "    all_adata = all_adata.concatenate(train_adata)\n",
    "    all_adata = all_adata.concatenate(test_adata)\n",
    "    sc.pp.filter_genes(all_adata, min_cells=1)\n",
    "    width = all_adata.X.shape[1]\n",
    "    \n",
    "    if (width < topgenes):\n",
    "        topgenes = width\n",
    "        \n",
    "    sc.pp.highly_variable_genes(all_adata, n_top_genes=topgenes)\n",
    "    all_adata.raw = all_adata\n",
    "    all_adata = all_adata[:, all_adata.var.highly_variable]\n",
    "\n",
    "    Train_adata = all_adata[:Trainadata_num]\n",
    "    Test_adata = all_adata[Trainadata_num:]\n",
    "\n",
    "    del all_adata\n",
    "    train_data, train_cells, train_cellTypes = getXY(gap, Train_adata, Traindata_paths)\n",
    "    Testdata_paths = []\n",
    "    Testdata_paths.append(Testdata_path)\n",
    "    test_data = getXY(gap, Test_adata, Label_path = None)\n",
    "    cell_types = train_cellTypes\n",
    "\n",
    "    Train_labels = getNewData(train_cells, cell_types)\n",
    "\n",
    "    return train_data, Train_labels, test_data, cell_types\n",
    "\n",
    "\n",
    "class TrainDataSet(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.length = len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.from_numpy(self.data)\n",
    "        label = torch.from_numpy(self.label)\n",
    "\n",
    "        return data[index], label[index]\n",
    "\n",
    "class TestDataSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "        self.length = len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.from_numpy(self.data)\n",
    "        return data[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f627b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class CIForm(nn.Module):\n",
    "    def __init__(self, input_dim, nhead=2, d_model=80, num_classes=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, dim_feedforward=1024, nhead=nhead, dropout=dropout\n",
    "        )\n",
    "        self.positionalEncoding = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
    "        self.pred_layer = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, mels):\n",
    "        out = mels.permute(1, 0, 2)\n",
    "        out = self.positionalEncoding(out)\n",
    "        out = self.encoder_layer(out)\n",
    "        out = out.transpose(0, 1)\n",
    "        out = out.mean(dim=1)\n",
    "        out = self.pred_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2fe108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(s,referece_datapaths,Train_names,Testdata_path,Testdata_name):\n",
    "    gap = s\n",
    "    topgenes = 2000\n",
    "    d_models = s\n",
    "    heads = 64\n",
    "\n",
    "    lr = 0.0001\n",
    "    dp = 0.1\n",
    "    batch_sizes = 256\n",
    "    n_epochs = 20\n",
    "\n",
    "    train_data, labels, query_data, cell_types = getData(gap, referece_datapaths,Train_names,Testdata_path,\n",
    "                                             Testdata_name,topgenes)\n",
    "\n",
    "    num_classes = np.unique(cell_types) + 1\n",
    "\n",
    "    model = CIForm(input_dim=d_models, nhead=heads, d_model=d_models,\n",
    "                       num_classes=num_classes,dropout=dp)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "    train_dataset = TrainDataSet(data=train_data, label=labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_sizes, shuffle=True,\n",
    "                              pin_memory=True)\n",
    "    test_dataset = TestDataSet(data=query_data)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_sizes, shuffle=False,\n",
    "                             pin_memory=True)\n",
    "    new_cellTypes = []\n",
    "    new_cellTypes.append(\"unassigned\")\n",
    "    new_cellTypes.extend(cell_types)\n",
    "\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        # model.train()\n",
    "        # These are used to record information in training.\n",
    "        train_loss = []\n",
    "        train_accs = []\n",
    "        train_f1s = []\n",
    "        for batch in tqdm(train_loader):\n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            data, labels = batch\n",
    "            logits = model(data)\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "            loss = criterion(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = logits.argmax(1)\n",
    "            preds = preds.cpu().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            f1 = f1_score(labels,preds,average='macro')\n",
    "            train_loss.append(loss.item())\n",
    "            train_accs.append(acc)\n",
    "            train_f1s.append(f1)\n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "        train_acc = sum(train_accs) / len(train_accs)\n",
    "        train_f1 = sum(train_f1s) / len(train_f1s)\n",
    "\n",
    "        print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}, f1 = {train_f1:.5f}\")\n",
    "\n",
    "        model.eval()\n",
    "        test_accs = []\n",
    "        test_f1s = []\n",
    "        y_predict = []\n",
    "        labelss = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            data, labels = batch\n",
    "            with torch.no_grad():\n",
    "                logits = model(data)\n",
    "            preds = logits.argmax(1)\n",
    "            preds = preds.cpu().numpy().tolist()\n",
    "            labels = labels.cpu().numpy().tolist()\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            f1 = f1_score(labels, preds, average='macro')\n",
    "            test_f1s.append(f1)\n",
    "            test_accs.append(acc)\n",
    "\n",
    "            y_predict.extend(preds)\n",
    "            labelss.extend(labels)\n",
    "        test_acc = sum(test_accs) / len(test_accs)\n",
    "        test_f1 = sum(test_f1s) / len(test_f1s)\n",
    "        print(\"---------------------------------------------end test---------------------------------------------\")\n",
    "        print(\"len(y_predict)\",len(y_predict))\n",
    "        all_acc = accuracy_score(labelss, y_predict)\n",
    "        all_f1 = f1_score(labelss, y_predict, average='macro')\n",
    "        print(\"all_acc:\", all_acc,\"all_f1:\", all_f1)\n",
    "\n",
    "        labelsss = []\n",
    "        y_predicts = []\n",
    "        for i in labelss:\n",
    "            labelsss.append(cell_types[i])\n",
    "        for i in y_predict:\n",
    "            y_predicts.append(cell_types[i])\n",
    "\n",
    "        log_dir = \"log/\"\n",
    "        log_txt = \"log/\"\n",
    "\n",
    "        if (not os.path.isdir(log_dir)):\n",
    "            os.makedirs(log_dir)\n",
    "\n",
    "        last_path = log_dir + str(n_epochs) + \"/\"\n",
    "        if (not os.path.isdir(last_path)):\n",
    "            os.makedirs(last_path)\n",
    "        with open(log_txt + \"end_norm.txt\", \"a\") as f:\n",
    "            f.writelines(\"log_dir:\" + last_path + \"\\n\")\n",
    "            f.writelines(\"acc:\" + str(all_acc) + \"\\n\")\n",
    "            f.writelines('f1:' + str(all_f1) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700553df",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1024\n",
    "\n",
    "x_Traindata_path = 'Dataset/imu/Sun/'\n",
    "Train_name = 'Sun'\n",
    "referece_datapaths = [x_Traindata_path]\n",
    "Train_names = [Train_name]\n",
    "\n",
    "Testdata_path = 'Dataset/imu/pbmc_10k_v3/'\n",
    "Testdata_name = 'pbmc_10k_v3'\n",
    "##Datasets: The rows represent the cells and the columns represent the genes\n",
    "main(s,referece_datapaths,Train_names,Testdata_path,Testdata_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
